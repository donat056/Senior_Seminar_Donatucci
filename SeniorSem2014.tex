\documentclass{sig-alternate}

\title{Modern Techniques for Energy Optimization for Green Cloud Computing}

\author{
\alignauthor
 		David Donatucci\\
        Division of Science and Mathematics\\
        University of Minnesota, Morris\\
        Morris, MN 56267\\
        donat056@morris.umn.edu\\
}
\date{} 

\begin{document}
\conferenceinfo{UMM CSci Senior Seminar Conference, December 2014}{Morris, MN}
\pagestyle{plain}

\maketitle

\begin{abstract}

Place abstract here

\end{abstract}

\keywords{Cloud Computing, Green Computing}

\section{Introduction} \label{sec:intro}

Cloud Computing has been growing exponentially in the last several years in order to accommodate a growing demand for internet services. Due to this growth, larger data centers are required to meet demand. With larger data centers, an increasing amount power is necessary for these data centers to fulfill demands. In 2010, 1.5\% of all energy consumed worldwide was from data centers. In 2000, only about one fourth of the energy was used to power data centers~\cite{Yanggratoke}. In light of these staggering numbers, much research has been devoted to reducing power consumption. So far, two different approaches have been implemented to combat power consumption: macro-based and micro-based methods. Macro-based methods focus on exploiting data centers in diverse geographical locations that have higher levels of renewable energy or cooler climates. Micro-based methods focus on efficient resource allocation of data center components~\cite{Hassan}. A description of cloud computing, evolutionary algorithms, and gossip-based protocol are provided in Section~\ref{Background}. Section~\ref{sec:MacAl} discusses a macro-based algorithm and Section~\ref{sec:MicAl} provides details on mirco-based algorithms. The results of these algorithms are presented in Section~\ref{sec:results}, and comparisons between these algorithms are presented in Section~\ref{sec:conclusion}.

\section{Background} 
\label{Background}

In order for the reader to fully understand the material presented in this paper, I will present some necessary background information.

\subsection{Cloud Computing}
\label{sec:Cloud Computing}

In the last several years, cloud computing has become a prevalent service. Cloud computing pertains to both the applications services provided via the Internet and the hardware and systems software in data centers. Inside these data centers are an exuberant amount of servers (the hardware) managed by middleware (software that communicates between servers). These components make up what is called the \emph{cloud}~\cite{Armbrust}. Usually, large IT firms called \emph{providers}, such as Google or Amazon, provide the hardware and system software for these large data centers. However, these large IT firms have extra servers and rent them to smaller companies providing a relatively cheap system to compute in the cloud. 

The workload on the cloud is amount of requests for service at a given time. In order to provide a high quality of service, the providers sign a service level agreement, \emph{SLA}, that requires them to fulfill these requests in a set amount of time. 

\subsection{Evolutionary Multi-objective Optimization Algorithms (EMOA)}
\label{sec:EMOA}

Evolutionary Computation~\cite{poli08:fieldguide} is based around the interactions of \emph{individuals}. Individuals are similar to organisms in biological evolution but contain a solution to a given problem. As in biological evolution, a group of individuals makes up a population. In the process of biological evolution and natural selection, organisms within a population compete in order to survive and reproduce. Those individuals best adapted to their environment have the best chance of fulfilling these objectives.  In an \emph{evolutionary multi-objective optimization algorithm}to, EMOA, there individuals also compete, but here those individuals that provide closer solutions to all user-defined optimizations have the best odds. The goal of EMOAs is to produce a set of individuals that provide quality solutions in a reasonable amount of time. 

At the beginning of an EMOA, an algorithm runs that randomly initializes a population. These individuals then compete in order to be selected for alteration towards a better solution. For the purposes of this paper, I will talk about binary tournament selection, although there are many different methods to select individuals to breed. Binary tournament selection is where two individuals are randomly chosen from the population, and the individual that is more optimized is selected as a parent. This is performed twice to obtain two parents.  These selected parents can propagate their genetic material to the next generation by two methods. The first and most common method is crossover, comparable to sexual reproduction, where two parents are selected from the current generation, and elements from each selected individual are combined to form a new individual in the next generation. The second method is mutation, in which an individual is selected and randomly altered, much like biological mutation. Crossover and mutation are utilized across multiple generations, until an optimized solution is found or until some sort of resource limit is reached.

\subsection{Gossip-based Protocol}
\label{sec:GBP}

\emph{Gossip-based}, GB, protocol acts exactly as the name gossip implies. A node which contains new information selects multiple nodes called \emph{peers} to spread new information to. The selection of peers is often probabilistic and therefore the number of peers is random. The act of spreading the information is called a \emph{round}. In the next round, each of the peers that received the information selects more peers to spread the information to. As more rounds are completed, all of the nodes start to have the same new information.~\cite{Yanggratoke}

\section{Macro-based Algorithms}
\label{sec:MacAl}

\emph{Green Monster}
%, GM,
is an framework proposed by Phan et al that uses geographictoal location to maximize energy savings. The EMOA in Green Monster uses three optimization objectives: renewable energy consumption (RE), cooling energy consumption (CE), and user-to-service distance (USD). In order to get the best results, Green Monster looks to maximize RE, and minimize both CE and USD. By minimizing the USD, Green Monster attempts to minimize the response time to assure a high quality of service specified by the SLAs. Also, minimizing the CE implies that the energy consumed in the data center will be more heavily used for processing. In \ref{sec:GMEMOA} I will discuss how the EMOA behind Green Monster works, and in \ref{sec:GMSims} I will look at simulations of Green Monster with real world data.~\cite{Phan}

\subsection{Green Monster EMOA}
\label{sec:GMEMOA}

Green Monster represents individuals an a configuration of all services (S$_{\text{\emph{i}}}$) in all data centers (D$_{\text{\emph{j}}}$). Each data center has a service capacity
%(C$_{\text{\emph{i}}}$) 
or the maximum workload a data center can handle. To initialize a population of \emph{N} individuals, the EMOA assigns random services to random data centers so that any given data center does not exceed the service capacity. If the service does exceed the service capacity, it will be assigned to the data center with the least workload. Upon completion, the EMOA uses binary tournament selection to select individuals for alteration. In this instance of binary tournament, the individual is selected by~\emph{constrained-dominance}. An individual, \emph{i},  is constrained-dominant to an individual, \emph{j}, if \emph{i} has the least amount of service capacity violations or if \emph{i} and \emph{j} do not have any violations \emph{i} is automatically constrained-dominant. When two parents are selected, crossover is performed determined by a crossover rate and two offspring are produced. Both of these offspring perform mutation determined by a mutation rate for each service. Mutating simply switches the current data center, D$_{\text{\emph{j}}}$, for a random new one. Phan et al then perform a local search on each S$_{\text{\emph{i}}}$  based on a local search rate that checks to see if any D$_{\text{\emph{k}}}$ where ${\text{\emph{k} ${\neq}$ j}}$, could improve all optimizations without violating the service capacity. If D$_{\text{\emph{k}}}$ meets the previous criteria, then D$_{\text{\emph{k}}}$ replaces D$_{\text{\emph{j}}}$ in S$_{\text{\emph{i}}}$. This is done repeatedly until the same amount of individuals in the parent generation are in the next generation. In order for the best individuals to permeate to the next generation, Phan et al combine both the parent and offspring generations and sort them based on constrained-dominance. Phan et al then take only the first \emph{N} individuals. This whole process repeats until a certain number of generations is reached. 

\subsection{Green Monster Simulations}
\label{sec:GMSims}
 
Several simulations of Green Monster have been conducted based on statistics of nine data center in nine different European countries: Denmark, Germany, Greece, Ireland, Italy, Netherlands, Spain, UK and Portugal. Temperature data was used from European Climate Assessment \& Dataset project which records temperatures real temperature data in Europe. These countries were chosen based on the wide variety of climates and renewable energy. The average renewable energy production data was pulled from each country from January 2007 to December 2009. In each data center there are between 8-200 servers and 16-400 services consisting of voice, data, and video based on the countries population. For the simulation, Phan et al decided that every server will have the same specifications and each type of service was evenly distributed to all types of services. Data center configurations are given in \ref{tab:DCConfig}.  Green Monsters EMOA in this simulation runs bi-weekly for twelve months. After running the EMOA with the configurations in \ref{tab:EMOAConfig}, the individual that is the most optimized overall is selected. Green Monster will migrate service, S$_{\text{\emph{i}}}$, to data center, D$_{\text{\emph{j}}}$, according to solution presented by the optimized individual.

\begin{table}[tb]
\begin{center}
\begin{tabular}{|l|l|}
    \hline
    \multicolumn{2}{|c|}{\textbf{Data Center Configurations}} \\
    \hline
    Number of Data Centers & 9 \\
    Total Number of Servers In Data Centers (\emph{N}) & 100 \\
    Service Types & 3 \\
    Average rate of requests per day & 2,000,000 \\
    Max Power Consumption in a Server & 400W \\
   	Min Power Consumption in a Server & 150W\\
    \hline
\end{tabular}
\caption{Data center configurations in Green Monster simulation}
\label{tab:DCConfig}
\end{center}
\end{table}

\begin{table}[tb]
\begin{center}
\begin{tabular}{|l|l|}
    \hline
    \multicolumn{2}{|c|}{\textbf{EMOA Configuration}} \\
    \hline
    Generations & 100 \\
    Population size (\emph{N}) & 100 \\
    Crossover rate & 90\% \\
    Mutation rate & 10\% \\
    Local Search rate & 10\% \\
    \hline
\end{tabular}
\caption{EMOA configurations in Green Monster}
\label{tab:EMOAConfig}
\end{center}
\end{table}



\section{Micro-based Algorithms} 
\label{sec:MicAl}

There are many different micro-based algorithms for a green cloud but I will choose to focus on two potential algorithms: GRMP-Q, a gossip-based allocation algorithm and the speed-scaling algorithm by Han et al. 

\subsection{Gossip-based Resource Allocation}
\label{sec:GBRA}
\emph{GRMP-Q} is middleware for a data center that utilizes gossip protocol to minimize the amount of servers running services. Usually, providers rent specific servers by the hour to smaller companies. This, however, is not efficient. A single server working at  \emph{workload capacity}, or the maximum amount of services that a single server can handle, will be much more efficient than three server working at one third of workload capacity. This is due to the minimum power level that a server must consume to be on. GRMP-Q attempts to migrate all services to the least amount of servers possible.  For simplicity, Han et al assume that all servers, \emph{N}, in a data center have identical specifications (power consumption, CPU, and memory capacities). For any given service, (S$_{\text{\emph{i}}}$), the demand, \emph{w$_{\text{s}}$}, can be spread across multiple servers. The equation for demand \emph{w$_{\text{(s,n)}}$} on a single server \emph{n}, is given by where \emph{$\alpha$} is the fraction of the demand on that server:
\[w_\emph{(s,n)} = \alpha_\emph{(s,n)} \times w_\emph{s} \text{\emph{~s.t.~}} \alpha_\emph{(s,n)} \geq 0,~ \sum_{n=1}^{N} \alpha_\emph{(s,n)} = 1  \]

Han et al then placed all of the \emph{$\alpha_\emph{(s,n)}$} for every service into a matrix called \emph{the configuration matrix}. The configuration matrix, A, shows how the data center's resources are allocated to services. At certain times, load changes, addition of services, or change in the number of servers will cause the configuration matrix to be updated. 

The first objective of GRMP-Q is to satisfy user demand by allocating enough resources so that the provider can satisfy the SLA. The second objective is to minimize power consumption. GRMP-Q does this by turning a server to stand-by if the total demand on the server is zero. If there is insufficient resources or the \emph{w$_{\text{(s,n)}}$} of a new service, S$_{\text{\emph{(i+1)}}}$, is greater than the workload capacity, the system will turn a stand-by server on. 

In order to transfer one service to another service there are three gossip-based processes that occur. The first process is initialization which initializes the gossip protocol for the current configuration matrix at a random server.  The second process chooses a peer by randomly selecting another server. After a peer is selected, the relative demand is calculated by taking $\sum$ of w(s,n) / workload of the server. 

\subsection{Speed-Scaling}
\label{sec:Speed}

\section{Results} 
\label{sec:results}
\subsection{Green Monster}
\label{sec:GM}
\subsection{GRMP-Q}
\label{sec:GRMP-Q}
\subsection{Speed Scaling}
\label{sec:SS}

\section{Conclusions} 
\label{sec:conclusion}



%\section*{Acknowledgements}

%David's work was supported by the Morris Academic Partners program at the University of Minnesota, Morris. Many thanks to Nicholas Cornhill and Emma Ireland for their early help in connecting evolutionary computation systems to Neo4j.

\pagebreak

\bibliographystyle{acm}
\bibliography{annotated_bibliography}

\end{document}